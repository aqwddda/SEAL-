{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fba3828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:45.506759Z",
     "iopub.status.busy": "2025-05-28T20:36:45.506759Z",
     "iopub.status.idle": "2025-05-28T20:36:52.208089Z",
     "shell.execute_reply": "2025-05-28T20:36:52.208089Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time, os\n",
    "import logging\n",
    "from config import Config\n",
    "import numpy as np\n",
    "import torch\n",
    "import out_manager as om\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch.nn import BCEWithLogitsLoss, Conv1d, MaxPool1d, ModuleList\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, GCNConv, SortAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75be216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:52.208089Z",
     "iopub.status.busy": "2025-05-28T20:36:52.208089Z",
     "iopub.status.idle": "2025-05-28T20:36:52.242895Z",
     "shell.execute_reply": "2025-05-28T20:36:52.242895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved to: ./out\\PubMed_k60_hop2_PubMed\\config.json\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "out_dir = om.get_existing_out_dir(config)\n",
    "om.save_config(config, out_dir)\n",
    "om.setup_logging(os.path.join(out_dir, \"ssseal_log.txt\"))\n",
    "seed = config.seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9acf1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:52.245409Z",
     "iopub.status.busy": "2025-05-28T20:36:52.245409Z",
     "iopub.status.idle": "2025-05-28T20:36:55.835045Z",
     "shell.execute_reply": "2025-05-28T20:36:55.835045Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = torch.load(f'./data/{config.dataset}/split/ssseal_train_data_k{config.scoresampler.k_min}_h{config.scoresampler.num_hops}_{config.version}.pt')\n",
    "val_data = torch.load(f'./data/{config.dataset}/split/ssseal_val_data_k{config.scoresampler.k_min}_h{config.scoresampler.num_hops}_{config.version}.pt')\n",
    "test_data = torch.load(f'./data/{config.dataset}/split/ssseal_test_data_k{config.scoresampler.k_min}_h{config.scoresampler.num_hops}_{config.version}.pt')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a05a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:55.835045Z",
     "iopub.status.busy": "2025-05-28T20:36:55.835045Z",
     "iopub.status.idle": "2025-05-28T20:36:55.845862Z",
     "shell.execute_reply": "2025-05-28T20:36:55.845862Z"
    }
   },
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, GNN=GCNConv, k=0.6):\n",
    "        super().__init__()\n",
    "\n",
    "        if k < 1:  # Transform percentile to number.\n",
    "            num_nodes = sorted([data.num_nodes for data in train_data])\n",
    "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
    "            k = int(max(10, k))\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(GNN(train_data[0].x.size(1), hidden_dim))\n",
    "        for i in range(0, num_layers - 1):\n",
    "            self.convs.append(GNN(hidden_dim, hidden_dim))\n",
    "        self.convs.append(GNN(hidden_dim, 1))\n",
    "\n",
    "        conv1d_channels = [16, 32]\n",
    "        total_latent_dim = hidden_dim * num_layers + 1\n",
    "        conv1d_kws = [total_latent_dim, 5]\n",
    "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
    "                            conv1d_kws[0])\n",
    "        self.pool = SortAggregation(k)\n",
    "        self.maxpool1d = MaxPool1d(2, 2)\n",
    "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "                            conv1d_kws[1], 1)\n",
    "        dense_dim = int((k - 2) / 2 + 1)\n",
    "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
    "        self.mlp = MLP([dense_dim, 128, 1], dropout=0.5, norm=None)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        xs = [x]\n",
    "        for conv in self.convs:\n",
    "            xs += [conv(xs[-1], edge_index).tanh()]\n",
    "        x = torch.cat(xs[1:], dim=-1)\n",
    "\n",
    "        # Global pooling.\n",
    "        x = self.pool(x, batch)\n",
    "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
    "        x = self.conv1(x).relu()\n",
    "        x = self.maxpool1d(x)\n",
    "        x = self.conv2(x).relu()\n",
    "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
    "\n",
    "        return self.mlp(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa4159b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:55.845862Z",
     "iopub.status.busy": "2025-05-28T20:36:55.845862Z",
     "iopub.status.idle": "2025-05-28T20:36:55.956725Z",
     "shell.execute_reply": "2025-05-28T20:36:55.956725Z"
    }
   },
   "outputs": [],
   "source": [
    "model = DGCNN(hidden_dim = config.ssseal.hidden_dim, num_layers = config.ssseal.num_layers, k = config.ssseal.k).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = config.ssseal.lr)\n",
    "loss_fn = BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c860f997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:55.956725Z",
     "iopub.status.busy": "2025-05-28T20:36:55.956725Z",
     "iopub.status.idle": "2025-05-28T20:36:55.963909Z",
     "shell.execute_reply": "2025-05-28T20:36:55.963909Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        data.batch = data.batch.long()\n",
    "        data.edge_index = data.edge_index.long()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = loss_fn(out.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea00f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:55.963909Z",
     "iopub.status.busy": "2025-05-28T20:36:55.963909Z",
     "iopub.status.idle": "2025-05-28T20:36:55.970741Z",
     "shell.execute_reply": "2025-05-28T20:36:55.970741Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        data.batch = data.batch.long()\n",
    "        data.edge_index = data.edge_index.long()\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        y_pred.append(logits.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "\n",
    "    return roc_auc_score(torch.cat(y_true), torch.cat(y_pred)), average_precision_score(torch.cat(y_true),torch.cat(y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e97de319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T20:36:55.972496Z",
     "iopub.status.busy": "2025-05-28T20:36:55.972496Z",
     "iopub.status.idle": "2025-05-28T20:48:45.114133Z",
     "shell.execute_reply": "2025-05-28T20:48:45.113630Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.3760 Train_AUC: 0.9505, Train_AP: 0.9519 Val_AUC: 0.9515, Val_AP: 0.9515 Test_AUC: 0.9533, Test_AP: 0.9543\n",
      "Epoch: 002, Loss: 0.2853 Train_AUC: 0.9559, Train_AP: 0.9572 Val_AUC: 0.9561, Val_AP: 0.9564 Test_AUC: 0.9584, Test_AP: 0.9595\n",
      "Epoch: 003, Loss: 0.2749 Train_AUC: 0.9579, Train_AP: 0.9596 Val_AUC: 0.9576, Val_AP: 0.9582 Test_AUC: 0.9595, Test_AP: 0.9611\n",
      "Epoch: 004, Loss: 0.2693 Train_AUC: 0.9591, Train_AP: 0.9608 Val_AUC: 0.9587, Val_AP: 0.9594 Test_AUC: 0.9602, Test_AP: 0.9619\n",
      "Epoch: 005, Loss: 0.2651 Train_AUC: 0.9600, Train_AP: 0.9615 Val_AUC: 0.9595, Val_AP: 0.9600 Test_AUC: 0.9605, Test_AP: 0.9621\n",
      "Epoch: 006, Loss: 0.2614 Train_AUC: 0.9610, Train_AP: 0.9624 Val_AUC: 0.9603, Val_AP: 0.9609 Test_AUC: 0.9616, Test_AP: 0.9631\n",
      "Epoch: 007, Loss: 0.2591 Train_AUC: 0.9613, Train_AP: 0.9628 Val_AUC: 0.9601, Val_AP: 0.9611 Test_AUC: 0.9620, Test_AP: 0.9636\n",
      "Epoch: 008, Loss: 0.2580 Train_AUC: 0.9622, Train_AP: 0.9635 Val_AUC: 0.9608, Val_AP: 0.9615 Test_AUC: 0.9625, Test_AP: 0.9639\n",
      "Epoch: 009, Loss: 0.2550 Train_AUC: 0.9629, Train_AP: 0.9640 Val_AUC: 0.9617, Val_AP: 0.9623 Test_AUC: 0.9622, Test_AP: 0.9636\n",
      "Epoch: 010, Loss: 0.2528 Train_AUC: 0.9629, Train_AP: 0.9639 Val_AUC: 0.9620, Val_AP: 0.9628 Test_AUC: 0.9620, Test_AP: 0.9633\n",
      "Epoch: 011, Loss: 0.2526 Train_AUC: 0.9634, Train_AP: 0.9644 Val_AUC: 0.9622, Val_AP: 0.9627 Test_AUC: 0.9624, Test_AP: 0.9637\n",
      "Epoch: 012, Loss: 0.2509 Train_AUC: 0.9637, Train_AP: 0.9646 Val_AUC: 0.9626, Val_AP: 0.9630 Test_AUC: 0.9620, Test_AP: 0.9634\n",
      "Epoch: 013, Loss: 0.2499 Train_AUC: 0.9638, Train_AP: 0.9646 Val_AUC: 0.9629, Val_AP: 0.9628 Test_AUC: 0.9620, Test_AP: 0.9632\n",
      "Epoch: 014, Loss: 0.2489 Train_AUC: 0.9640, Train_AP: 0.9649 Val_AUC: 0.9635, Val_AP: 0.9635 Test_AUC: 0.9621, Test_AP: 0.9633\n",
      "Epoch: 015, Loss: 0.2482 Train_AUC: 0.9645, Train_AP: 0.9653 Val_AUC: 0.9630, Val_AP: 0.9632 Test_AUC: 0.9629, Test_AP: 0.9641\n",
      "Epoch: 016, Loss: 0.2476 Train_AUC: 0.9647, Train_AP: 0.9655 Val_AUC: 0.9637, Val_AP: 0.9637 Test_AUC: 0.9626, Test_AP: 0.9638\n",
      "Epoch: 017, Loss: 0.2464 Train_AUC: 0.9652, Train_AP: 0.9660 Val_AUC: 0.9640, Val_AP: 0.9638 Test_AUC: 0.9633, Test_AP: 0.9644\n",
      "Epoch: 018, Loss: 0.2460 Train_AUC: 0.9655, Train_AP: 0.9662 Val_AUC: 0.9643, Val_AP: 0.9641 Test_AUC: 0.9633, Test_AP: 0.9644\n",
      "Epoch: 019, Loss: 0.2445 Train_AUC: 0.9656, Train_AP: 0.9663 Val_AUC: 0.9643, Val_AP: 0.9637 Test_AUC: 0.9632, Test_AP: 0.9642\n",
      "Epoch: 020, Loss: 0.2433 Train_AUC: 0.9657, Train_AP: 0.9664 Val_AUC: 0.9642, Val_AP: 0.9639 Test_AUC: 0.9635, Test_AP: 0.9646\n",
      "Epoch: 021, Loss: 0.2433 Train_AUC: 0.9660, Train_AP: 0.9666 Val_AUC: 0.9645, Val_AP: 0.9640 Test_AUC: 0.9634, Test_AP: 0.9646\n",
      "Epoch: 022, Loss: 0.2428 Train_AUC: 0.9661, Train_AP: 0.9667 Val_AUC: 0.9650, Val_AP: 0.9645 Test_AUC: 0.9638, Test_AP: 0.9649\n",
      "Epoch: 023, Loss: 0.2412 Train_AUC: 0.9662, Train_AP: 0.9669 Val_AUC: 0.9642, Val_AP: 0.9637 Test_AUC: 0.9640, Test_AP: 0.9650\n",
      "Epoch: 024, Loss: 0.2413 Train_AUC: 0.9664, Train_AP: 0.9668 Val_AUC: 0.9647, Val_AP: 0.9644 Test_AUC: 0.9638, Test_AP: 0.9648\n",
      "Epoch: 025, Loss: 0.2413 Train_AUC: 0.9668, Train_AP: 0.9673 Val_AUC: 0.9645, Val_AP: 0.9640 Test_AUC: 0.9645, Test_AP: 0.9655\n",
      "Epoch: 026, Loss: 0.2406 Train_AUC: 0.9671, Train_AP: 0.9676 Val_AUC: 0.9650, Val_AP: 0.9645 Test_AUC: 0.9644, Test_AP: 0.9653\n",
      "Epoch: 027, Loss: 0.2405 Train_AUC: 0.9668, Train_AP: 0.9673 Val_AUC: 0.9650, Val_AP: 0.9644 Test_AUC: 0.9645, Test_AP: 0.9655\n",
      "Epoch: 028, Loss: 0.2390 Train_AUC: 0.9668, Train_AP: 0.9674 Val_AUC: 0.9650, Val_AP: 0.9647 Test_AUC: 0.9642, Test_AP: 0.9654\n",
      "Epoch: 029, Loss: 0.2397 Train_AUC: 0.9670, Train_AP: 0.9675 Val_AUC: 0.9646, Val_AP: 0.9642 Test_AUC: 0.9641, Test_AP: 0.9652\n",
      "Epoch: 030, Loss: 0.2394 Train_AUC: 0.9672, Train_AP: 0.9677 Val_AUC: 0.9653, Val_AP: 0.9648 Test_AUC: 0.9642, Test_AP: 0.9652\n",
      "Epoch: 031, Loss: 0.2380 Train_AUC: 0.9673, Train_AP: 0.9678 Val_AUC: 0.9651, Val_AP: 0.9650 Test_AUC: 0.9642, Test_AP: 0.9653\n",
      "Epoch: 032, Loss: 0.2375 Train_AUC: 0.9675, Train_AP: 0.9680 Val_AUC: 0.9649, Val_AP: 0.9646 Test_AUC: 0.9646, Test_AP: 0.9657\n",
      "Epoch: 033, Loss: 0.2370 Train_AUC: 0.9679, Train_AP: 0.9683 Val_AUC: 0.9651, Val_AP: 0.9646 Test_AUC: 0.9645, Test_AP: 0.9655\n",
      "Epoch: 034, Loss: 0.2372 Train_AUC: 0.9677, Train_AP: 0.9682 Val_AUC: 0.9654, Val_AP: 0.9649 Test_AUC: 0.9644, Test_AP: 0.9654\n",
      "Epoch: 035, Loss: 0.2367 Train_AUC: 0.9676, Train_AP: 0.9681 Val_AUC: 0.9652, Val_AP: 0.9647 Test_AUC: 0.9640, Test_AP: 0.9652\n",
      "Epoch: 036, Loss: 0.2360 Train_AUC: 0.9682, Train_AP: 0.9686 Val_AUC: 0.9654, Val_AP: 0.9646 Test_AUC: 0.9643, Test_AP: 0.9654\n",
      "Epoch: 037, Loss: 0.2351 Train_AUC: 0.9682, Train_AP: 0.9687 Val_AUC: 0.9650, Val_AP: 0.9645 Test_AUC: 0.9645, Test_AP: 0.9658\n",
      "Epoch: 038, Loss: 0.2348 Train_AUC: 0.9683, Train_AP: 0.9687 Val_AUC: 0.9650, Val_AP: 0.9644 Test_AUC: 0.9644, Test_AP: 0.9655\n",
      "Epoch: 039, Loss: 0.2340 Train_AUC: 0.9684, Train_AP: 0.9688 Val_AUC: 0.9648, Val_AP: 0.9643 Test_AUC: 0.9646, Test_AP: 0.9658\n",
      "Epoch: 040, Loss: 0.2336 Train_AUC: 0.9686, Train_AP: 0.9690 Val_AUC: 0.9653, Val_AP: 0.9648 Test_AUC: 0.9647, Test_AP: 0.9659\n",
      "Epoch: 041, Loss: 0.2344 Train_AUC: 0.9688, Train_AP: 0.9692 Val_AUC: 0.9649, Val_AP: 0.9643 Test_AUC: 0.9642, Test_AP: 0.9652\n",
      "Epoch: 042, Loss: 0.2326 Train_AUC: 0.9685, Train_AP: 0.9689 Val_AUC: 0.9652, Val_AP: 0.9648 Test_AUC: 0.9643, Test_AP: 0.9654\n",
      "Epoch: 043, Loss: 0.2334 Train_AUC: 0.9690, Train_AP: 0.9694 Val_AUC: 0.9654, Val_AP: 0.9648 Test_AUC: 0.9644, Test_AP: 0.9654\n",
      "Epoch: 044, Loss: 0.2321 Train_AUC: 0.9687, Train_AP: 0.9692 Val_AUC: 0.9652, Val_AP: 0.9647 Test_AUC: 0.9641, Test_AP: 0.9655\n",
      "Epoch: 045, Loss: 0.2315 Train_AUC: 0.9690, Train_AP: 0.9694 Val_AUC: 0.9649, Val_AP: 0.9643 Test_AUC: 0.9641, Test_AP: 0.9654\n",
      "Epoch: 046, Loss: 0.2317 Train_AUC: 0.9689, Train_AP: 0.9694 Val_AUC: 0.9649, Val_AP: 0.9640 Test_AUC: 0.9641, Test_AP: 0.9652\n",
      "Epoch: 047, Loss: 0.2309 Train_AUC: 0.9696, Train_AP: 0.9699 Val_AUC: 0.9650, Val_AP: 0.9644 Test_AUC: 0.9647, Test_AP: 0.9655\n",
      "Epoch: 048, Loss: 0.2307 Train_AUC: 0.9693, Train_AP: 0.9697 Val_AUC: 0.9649, Val_AP: 0.9645 Test_AUC: 0.9643, Test_AP: 0.9655\n",
      "Epoch: 049, Loss: 0.2311 Train_AUC: 0.9695, Train_AP: 0.9699 Val_AUC: 0.9650, Val_AP: 0.9643 Test_AUC: 0.9649, Test_AP: 0.9659\n",
      "Epoch: 050, Loss: 0.2299 Train_AUC: 0.9695, Train_AP: 0.9699 Val_AUC: 0.9648, Val_AP: 0.9644 Test_AUC: 0.9644, Test_AP: 0.9655\n",
      "Median time per epoch: 251.2893sFinal Test AUC: 0.9644, AP: 0.9654\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "best_val_auc = final_test_auc = final_test_ap = 0\n",
    "\n",
    "for epoch in range(1, 1 + config.ssseal.epochs):\n",
    "    start = time.time()\n",
    "    loss = train()\n",
    "    train_auc, train_ap = test(train_loader)\n",
    "    val_auc, val_ap = test(val_loader)\n",
    "    test_auc, test_ap = test(test_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "        final_test_ap = test_ap\n",
    "\n",
    "    logging.info(f'Epoch: {epoch:03d}, Loss: {loss:.4f} '\n",
    "             f'Train_AUC: {train_auc:.4f}, Train_AP: {train_ap:.4f} '\n",
    "             f'Val_AUC: {val_auc:.4f}, Val_AP: {val_ap:.4f} '\n",
    "             f'Test_AUC: {test_auc:.4f}, Test_AP: {test_ap:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "    \n",
    "logging.info(f'Median time per epoch: {torch.tensor(times).median():.4f}s'\n",
    "             f'Final Test AUC: {final_test_auc:.4f}, AP: {final_test_ap:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
