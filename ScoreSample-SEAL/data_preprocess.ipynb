{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809b10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.data import Data\n",
    "from config import Config\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "config = Config()\n",
    "seed = config.seed\n",
    "random.seed(config.seed)\n",
    "torch.manual_seed(seed)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "949717df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid('./data', 'Cora')\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "torch.save(train_data, './data/Cora/split/train_data.pt')\n",
    "torch.save(val_data, './data/Cora/split/val_data.pt')\n",
    "torch.save(test_data, './data/Cora/split/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83a9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = np.loadtxt('./data/Celegans/raw/Celegans.txt').astype(int).T\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "torch.save(data, './data/Celegans/processed/data.pt')\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "torch.save(train_data, './data/Celegans/split/train_data.pt')\n",
    "torch.save(val_data, './data/Celegans/split/val_data.pt')\n",
    "torch.save(test_data, './data/Celegans/split/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d63655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[333, 333], edge_index=[2, 4252])\n"
     ]
    }
   ],
   "source": [
    "edge_list = np.loadtxt('./data/USAir/raw/USAir.txt')[:, :2].astype(int).T\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)\n",
    "num_nodes = edge_index.max().item() + 1\n",
    "x = torch.eye(num_nodes, dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "torch.save(data, './data/USAir/processed/data.pt')\n",
    "print(data)\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "torch.save(train_data, './data/USAir/split/train_data.pt')\n",
    "torch.save(val_data, './data/USAir/split/val_data.pt')\n",
    "torch.save(test_data, './data/USAir/split/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b88192",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid('./data', 'PubMed')\n",
    "data = dataset[0]\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "torch.save(train_data, './data/PubMed/split/train_data.pt')\n",
    "torch.save(val_data, './data/PubMed/split/val_data.pt')\n",
    "torch.save(test_data, './data/PubMed/split/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c1ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid('./data', 'CiteSeer')\n",
    "data = dataset[0]\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "torch.save(train_data, './data/CiteSeer/split/train_data.pt')\n",
    "torch.save(val_data, './data/CiteSeer/split/val_data.pt')\n",
    "torch.save(test_data, './data/CiteSeer/split/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4965, 512], edge_index=[2, 37094])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('./data/Github/processed/github_sub_data.pt')\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "torch.save(train_data, './data/Github/split/train_data.pt')\n",
    "torch.save(val_data, './data/Github/split/val_data.pt')\n",
    "torch.save(test_data, './data/Github/split/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbdff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[37700, 512], edge_index=[2, 566446], pos_edge_label=[283223], pos_edge_label_index=[2, 283223], neg_edge_label=[283223], neg_edge_label_index=[2, 283223])\n",
      "Data(x=[37700, 512], edge_index=[2, 566446], y=[28322], pos_edge_label_index=[2, 14161], neg_edge_label_index=[2, 14161])\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('./data/Github/processed/github_full_data.pt')\n",
    "transform = T.Compose([T.NormalizeFeatures(), T.RandomLinkSplit(num_val=0.01, num_test=0.01, is_undirected=True, split_labels=True)])\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(train_data)\n",
    "\n",
    "# --- 采样正例 ---\n",
    "num_train_pos = train_data.pos_edge_label_index.size(1)\n",
    "num_sampled_pos = int(num_train_pos * 0.05)\n",
    "\n",
    "sampled_indices_pos = random.sample(range(num_train_pos), num_sampled_pos)\n",
    "sampled_pos_edge_label_index = train_data.pos_edge_label_index[:, sampled_indices_pos]\n",
    "\n",
    "num_train_neg = train_data.neg_edge_label_index.size(1)\n",
    "num_sampled_neg = int(num_train_neg * 0.05)\n",
    "\n",
    "sampled_indices_neg = random.sample(range(num_train_neg), num_sampled_neg)\n",
    "sampled_neg_edge_label_index = train_data.neg_edge_label_index[:, sampled_indices_neg]\n",
    "\n",
    "train_data = Data(\n",
    "    x=train_data.x,\n",
    "    edge_index=train_data.edge_index,\n",
    "    pos_edge_label_index=sampled_pos_edge_label_index,\n",
    "    neg_edge_label_index=sampled_neg_edge_label_index,\n",
    "    y=torch.cat([torch.ones(num_sampled_pos), torch.zeros(num_sampled_neg)]).long()\n",
    ")\n",
    "print(train_data)\n",
    "\n",
    "torch.save(train_data, './data/Github/split/train_data.pt')\n",
    "torch.save(val_data, './data/Github/split/val_data.pt')\n",
    "torch.save(test_data, './data/Github/split/test_data.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
