{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fb66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from model.score_gnn import ScoreGNN, DotProductPredictor, HadamardMLPPredictor, ConcatMLPPredictor\n",
    "\n",
    "seed = 2025\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15c8cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubgraphSampler:\n",
    "    def __init__(self, model, predictor, k_top=20, num_hops = 5, device = device):\n",
    "        self.model = model.eval()\n",
    "        self.predictor = predictor.eval()\n",
    "        self.k_top = k_top\n",
    "        self.num_hops = num_hops\n",
    "        self.device = device\n",
    "    \n",
    "    def process(self):\n",
    "        train_data = torch.load('./data/Cora/split/train_data.pt')\n",
    "        val_data = torch.load('./data/Cora/split/val_data.pt')\n",
    "        test_data = torch.load('./data/Cora/split/test_data.pt')\n",
    "\n",
    "        train_data = train_data.to(self.device)\n",
    "        val_data = val_data.to(self.device)\n",
    "        test_data = test_data.to(self.device)\n",
    "\n",
    "        train_pos_data_list = self.sample_all_edges(\n",
    "        train_data, train_data.pos_edge_label_index, 1)\n",
    "        train_neg_data_list = self.sample_all_edges(\n",
    "        train_data, train_data.neg_edge_label_index, 0)\n",
    "\n",
    "        val_pos_data_list = self.sample_all_edges(\n",
    "        val_data, val_data.pos_edge_label_index, 1)\n",
    "        val_neg_data_list = self.sample_all_edges(\n",
    "        val_data, val_data.neg_edge_label_index, 0)\n",
    "\n",
    "        test_pos_data_list = self.sample_all_edges(\n",
    "        test_data, test_data.pos_edge_label_index, 1)\n",
    "        test_neg_data_list = self.sample_all_edges(\n",
    "        test_data, test_data.neg_edge_label_index, 0)\n",
    "\n",
    "        train_data_list = train_pos_data_list + train_neg_data_list\n",
    "        val_data_list = val_pos_data_list + val_neg_data_list\n",
    "        test_data_list = test_pos_data_list + test_neg_data_list\n",
    "\n",
    "        torch.save(train_data_list, './data/Cora/split/ssseal_train_data.pt')\n",
    "        torch.save(val_data_list, './data/Cora/split/ssseal_val_data.pt')\n",
    "        torch.save(test_data_list, './data/Cora/split/ssseal_test_data.pt')\n",
    "        print(\"All processed data have been saved.\")\n",
    "    \n",
    "    def sample_all_edges(self, data, edge_label_index, y):\n",
    "        data_list = []\n",
    "        for src, dst in edge_label_index.t().tolist():\n",
    "            data_list.append(self.sample_subgraph(src, dst, data, y))\n",
    "        return data_list\n",
    "    \n",
    "    def sample_subgraph(self, src, dst, data, y):\n",
    "        # 采k-hop子图，得到子图节点的新编号、子图内边、mapping\n",
    "        sub_node_index, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "            [src, dst], self.num_hops, data.edge_index, relabel_nodes=True)\n",
    "        sub_edge_index = sub_edge_index.to(self.device)\n",
    "\n",
    "        #子图全部节点初始特征向量(sub.num_of_node, data.x.size(1))\n",
    "        sub_x = data.x[sub_node_index].to(self.device)\n",
    "        sub_src, sub_dst = mapping.tolist()\n",
    "        \n",
    "        #构建子图的data\n",
    "        sub_data = Data(x = sub_x,edge_index = sub_edge_index).to(self.device)\n",
    "        #获取子图的所有节点分数字典（不包含src和dst）\n",
    "        scores_dist, sub_node_emb = self.get_subgraph_scores(sub_src, sub_dst, sub_data)\n",
    "        # 分数从高到低取前top_k\n",
    "        topk_neighbors = heapq.nlargest(self.k_top, scores_dist, key=scores_dist.get)\n",
    "\n",
    "        # 源点和目标点在子图的编号\n",
    "        final_nodes = [sub_src, sub_dst] + topk_neighbors\n",
    "        final_nodes = list(set(final_nodes))  # 防止重复\n",
    "        final_nodes.sort()  # 方便后面重新映射\n",
    "\n",
    "        # 旧编号到新编号的映射\n",
    "        node_id_map = {old: new for new, old in enumerate(final_nodes)}\n",
    "\n",
    "        # 新的x\n",
    "        final_x = sub_node_emb[final_nodes]\n",
    "\n",
    "        # mask边：只保留两个端点都在final_nodes内的边\n",
    "        final_nodes_tensor = torch.tensor(final_nodes, device=self.device)\n",
    "        mask = torch.isin(sub_edge_index[0], final_nodes_tensor) & \\\n",
    "            torch.isin(sub_edge_index[1], final_nodes_tensor)\n",
    "        final_edge_index = sub_edge_index[:, mask]\n",
    "\n",
    "        # 重新编号edge_index\n",
    "        final_edge_index = torch.stack([\n",
    "            torch.tensor([node_id_map[int(i)] for i in final_edge_index[0].tolist()], device=self.device),\n",
    "            torch.tensor([node_id_map[int(i)] for i in final_edge_index[1].tolist()], device=self.device)\n",
    "        ], dim=0)\n",
    "\n",
    "        #去除 src-dst 之间的边（无向图记得两个方向都删！）\n",
    "        src_new = node_id_map[sub_src]\n",
    "        dst_new = node_id_map[sub_dst]\n",
    "        mask1 = (final_edge_index[0] != src_new) | (final_edge_index[1] != dst_new)\n",
    "        mask2 = (final_edge_index[0] != dst_new) | (final_edge_index[1] != src_new)\n",
    "        mask = mask1 & mask2\n",
    "        final_edge_index = final_edge_index[:, mask]\n",
    "\n",
    "        final_sub_data = Data(x=final_x, edge_index=final_edge_index, y = y)\n",
    "        return final_sub_data\n",
    "    \n",
    "    def get_subgraph_scores(self, src, dst, data):\n",
    "        with torch.no_grad():\n",
    "            node_emb =self.model(data.x, data.edge_index)\n",
    "\n",
    "            #构建所有src和dst分别到子图所有节点的组合(不包含互相)\n",
    "            candidates = [i for i in range(data.num_nodes) if i != src and i != dst]\n",
    "            src_1 = torch.tensor([src] * len(candidates), dtype=torch.long)\n",
    "            dst_1 = torch.tensor(candidates, dtype=torch.long)\n",
    "            src_2 = torch.tensor([dst] * len(candidates), dtype=torch.long)\n",
    "            dst_2 = torch.tensor(candidates, dtype=torch.long)\n",
    "            edge_label_index_1 = torch.stack([src_1, dst_1], dim=0)\n",
    "            edge_label_index_2 = torch.stack([src_2, dst_2], dim=0)\n",
    "\n",
    "            scores_1 = self.predictor(node_emb, edge_label_index_1)\n",
    "            scores_2 = self.predictor(node_emb, edge_label_index_2)\n",
    "            scores = (scores_1 + scores_2) / 2\n",
    "            scores_dist = {i: float(score) for i, score in zip(candidates, scores)}\n",
    "        return scores_dist, node_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2508e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'hidden_dim': 256,\n",
    "    'output_dim': 128,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 200,\n",
    "    'predictor': HadamardMLPPredictor(input_dim=128).to(device), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45f70e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and predictor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "train_data = torch.load('./data/Cora/split/train_data.pt')\n",
    "model = ScoreGNN(train_data.num_features, args['hidden_dim'], args['output_dim'], args['num_layers'], args['dropout']).to(device)\n",
    "predictor = args['predictor']\n",
    "\n",
    "# 加载参数（假设你的文件结构是这样保存的）\n",
    "checkpoint = torch.load('./model/scoregnn.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "predictor.load_state_dict(checkpoint['predictor'])\n",
    "\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "print(\"Model and predictor loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dbb03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processed data have been saved.\n"
     ]
    }
   ],
   "source": [
    "sampler = SubgraphSampler(model = model, predictor = predictor)\n",
    "sampler.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
