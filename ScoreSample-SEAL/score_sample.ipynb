{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89fb66b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T09:12:50.507933Z",
     "iopub.status.busy": "2025-05-27T09:12:50.507933Z",
     "iopub.status.idle": "2025-05-27T09:12:56.163994Z",
     "shell.execute_reply": "2025-05-27T09:12:56.163994Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from itertools import chain\n",
    "from config import Config\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph, to_scipy_sparse_matrix\n",
    "from model.score_gnn import ScoreGNN\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "\n",
    "config = Config()\n",
    "seed = config.seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c8cff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T09:12:56.168005Z",
     "iopub.status.busy": "2025-05-27T09:12:56.167003Z",
     "iopub.status.idle": "2025-05-27T09:12:56.182092Z",
     "shell.execute_reply": "2025-05-27T09:12:56.181086Z"
    }
   },
   "outputs": [],
   "source": [
    "class SubgraphSampler:\n",
    "    def __init__(self, model, predictor, k_top, num_hops, device = device):\n",
    "        self.model = model.eval()\n",
    "        self.predictor = predictor.eval()\n",
    "        self.k_top = k_top\n",
    "        self.num_hops = num_hops\n",
    "        self.device = device\n",
    "    \n",
    "    def process(self):\n",
    "        train_data = torch.load('./data/Cora/split/train_data.pt')\n",
    "        val_data = torch.load('./data/Cora/split/val_data.pt')\n",
    "        test_data = torch.load('./data/Cora/split/test_data.pt')\n",
    "\n",
    "        train_data = train_data.to(self.device)\n",
    "        val_data = val_data.to(self.device)\n",
    "        test_data = test_data.to(self.device)\n",
    "\n",
    "        self._max_z = 0\n",
    "\n",
    "        train_pos_data_list = self.sample_all_edges(\n",
    "        train_data, train_data.pos_edge_label_index, 1)\n",
    "        train_neg_data_list = self.sample_all_edges(\n",
    "        train_data, train_data.neg_edge_label_index, 0)\n",
    "\n",
    "        val_pos_data_list = self.sample_all_edges(\n",
    "        val_data, val_data.pos_edge_label_index, 1)\n",
    "        val_neg_data_list = self.sample_all_edges(\n",
    "        val_data, val_data.neg_edge_label_index, 0)\n",
    "\n",
    "        test_pos_data_list = self.sample_all_edges(\n",
    "        test_data, test_data.pos_edge_label_index, 1)\n",
    "        test_neg_data_list = self.sample_all_edges(\n",
    "        test_data, test_data.neg_edge_label_index, 0)\n",
    "\n",
    "        for data in chain(train_pos_data_list, train_neg_data_list,\n",
    "                          val_pos_data_list, val_neg_data_list,\n",
    "                          test_pos_data_list, test_neg_data_list):\n",
    "            # We solely learn links from structure, dropping any node features:\n",
    "            data.x = F.one_hot(data.z, self._max_z + 1).to(torch.float)\n",
    "\n",
    "        train_data_list = train_pos_data_list + train_neg_data_list\n",
    "        val_data_list = val_pos_data_list + val_neg_data_list\n",
    "        test_data_list = test_pos_data_list + test_neg_data_list\n",
    "\n",
    "        torch.save(train_data_list, f'./data/Cora/split/ssseal_train_data_k{self.k_top}_h{self.num_hops}.pt')\n",
    "        torch.save(val_data_list, f'./data/Cora/split/ssseal_val_data_k{self.k_top}_h{self.num_hops}.pt')\n",
    "        torch.save(test_data_list, f'./data/Cora/split/ssseal_test_data_k{self.k_top}_h{self.num_hops}.pt')\n",
    "        print(\"All processed data have been saved.\")\n",
    "    \n",
    "    def sample_all_edges(self, data, edge_label_index, y):\n",
    "        data_list = []\n",
    "        for src, dst in edge_label_index.t().tolist():\n",
    "            data_list.append(self.sample_subgraph(src, dst, data, y))\n",
    "        return data_list\n",
    "    \n",
    "    def sample_subgraph(self, src, dst, data, y):\n",
    "        # 采k-hop子图，得到子图节点的新编号、子图内边、mapping\n",
    "        sub_node_index, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "            [src, dst], self.num_hops, data.edge_index, relabel_nodes=True)\n",
    "        sub_edge_index = sub_edge_index.to(self.device)\n",
    "\n",
    "        #子图全部节点初始特征向量(sub.num_of_node, data.x.size(1))\n",
    "        sub_x = data.x[sub_node_index].to(self.device)\n",
    "        sub_src, sub_dst = mapping.tolist()\n",
    "        \n",
    "        #构建子图的data\n",
    "        sub_data = Data(x = sub_x,edge_index = sub_edge_index).to(self.device)\n",
    "        #获取子图的所有节点分数字典（不包含src和dst）\n",
    "        # scores_dist, sub_node_emb = self.get_subgraph_scores(sub_src, sub_dst, sub_data)\n",
    "        scores_dist, _ = self.get_subgraph_scores(sub_src, sub_dst, sub_data)\n",
    "        # 分数从高到低取前top_k\n",
    "        topk_neighbors = heapq.nlargest(self.k_top, scores_dist, key=scores_dist.get)\n",
    "\n",
    "        # 源点和目标点在子图的编号\n",
    "        final_nodes = [sub_src, sub_dst] + topk_neighbors\n",
    "        final_nodes = list(set(final_nodes))  # 防止重复\n",
    "        final_nodes.sort()  # 方便后面重新映射\n",
    "\n",
    "        # 旧编号到新编号的映射\n",
    "        node_id_map = {old: new for new, old in enumerate(final_nodes)}\n",
    "\n",
    "        # 新的x\n",
    "        # final_x = sub_node_emb[final_nodes]\n",
    "\n",
    "        # mask边：只保留两个端点都在final_nodes内的边\n",
    "        final_nodes_tensor = torch.tensor(final_nodes, device=self.device)\n",
    "        mask = torch.isin(sub_edge_index[0], final_nodes_tensor) & \\\n",
    "            torch.isin(sub_edge_index[1], final_nodes_tensor)\n",
    "        final_edge_index = sub_edge_index[:, mask]\n",
    "\n",
    "        # 重新编号edge_index\n",
    "        final_edge_index = torch.stack([\n",
    "            torch.tensor([node_id_map[int(i)] for i in final_edge_index[0].tolist()], device=self.device),\n",
    "            torch.tensor([node_id_map[int(i)] for i in final_edge_index[1].tolist()], device=self.device)\n",
    "        ], dim=0)\n",
    "\n",
    "        #去除 src-dst 之间的边（无向图记得两个方向都删！）\n",
    "        src_new = node_id_map[sub_src]\n",
    "        dst_new = node_id_map[sub_dst]\n",
    "        mask1 = (final_edge_index[0] != src_new) | (final_edge_index[1] != dst_new)\n",
    "        mask2 = (final_edge_index[0] != dst_new) | (final_edge_index[1] != src_new)\n",
    "        mask = mask1 & mask2\n",
    "        final_edge_index = final_edge_index[:, mask]\n",
    "\n",
    "        z = self.drnl_node_labeling(final_edge_index, src_new, dst_new, num_nodes = len(final_nodes))\n",
    "\n",
    "        final_sub_data = Data(x = sub_x, z = z, edge_index = final_edge_index, y = y)\n",
    "        return final_sub_data\n",
    "    \n",
    "    def get_subgraph_scores(self, src, dst, data):\n",
    "        with torch.no_grad():\n",
    "            node_emb =self.model(data.x, data.edge_index)\n",
    "\n",
    "            #构建所有src和dst分别到子图所有节点的组合(不包含互相)\n",
    "            candidates = [i for i in range(data.num_nodes) if i != src and i != dst]\n",
    "            src_1 = torch.tensor([src] * len(candidates), dtype=torch.long)\n",
    "            dst_1 = torch.tensor(candidates, dtype=torch.long)\n",
    "            src_2 = torch.tensor([dst] * len(candidates), dtype=torch.long)\n",
    "            dst_2 = torch.tensor(candidates, dtype=torch.long)\n",
    "            edge_label_index_1 = torch.stack([src_1, dst_1], dim=0)\n",
    "            edge_label_index_2 = torch.stack([src_2, dst_2], dim=0)\n",
    "\n",
    "            scores_1 = self.predictor(node_emb, edge_label_index_1)\n",
    "            scores_2 = self.predictor(node_emb, edge_label_index_2)\n",
    "            scores = (scores_1 + scores_2) / 2\n",
    "            scores_dist = {i: float(score) for i, score in zip(candidates, scores)}\n",
    "        return scores_dist, node_emb\n",
    "    \n",
    "    def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
    "        # Double-radius node labeling (DRNL).\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
    "\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "        dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
    "                                 indices=src)\n",
    "        dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "        dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "        dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
    "                                 indices=dst - 1)\n",
    "        dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "        dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "        dist = dist2src + dist2dst\n",
    "        dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "        z = 1 + torch.min(dist2src, dist2dst)\n",
    "        z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "        z[src] = 1.\n",
    "        z[dst] = 1.\n",
    "        z[torch.isnan(z)] = 0.\n",
    "\n",
    "        self._max_z = max(int(z.max()), self._max_z)\n",
    "\n",
    "        return z.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f70e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T09:12:56.185094Z",
     "iopub.status.busy": "2025-05-27T09:12:56.185094Z",
     "iopub.status.idle": "2025-05-27T09:12:56.277872Z",
     "shell.execute_reply": "2025-05-27T09:12:56.276860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and predictor loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model = ScoreGNN(config.data_init_num_features, hidden_dim = config.scoregnn.hidden_dim, \n",
    "                 output_dim = config.scoregnn.output_dim , num_layers = config.scoregnn.num_layers, \n",
    "                 dropout = config.scoregnn.dropout).to(device)\n",
    "predictor = config.predictor\n",
    "\n",
    "# 加载参数（假设你的文件结构是这样保存的）\n",
    "checkpoint = torch.load('./model/scoregnn.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "predictor.load_state_dict(checkpoint['predictor'])\n",
    "\n",
    "model.eval()\n",
    "predictor.eval()\n",
    "print(\"Model and predictor loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbb03a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T09:12:56.281385Z",
     "iopub.status.busy": "2025-05-27T09:12:56.280387Z",
     "iopub.status.idle": "2025-05-27T09:15:29.692348Z",
     "shell.execute_reply": "2025-05-27T09:15:29.692348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All processed data have been saved.\n"
     ]
    }
   ],
   "source": [
    "sampler = SubgraphSampler(model = model, predictor = predictor, k_top = config.k_top, num_hops = config.num_hops)\n",
    "sampler.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
